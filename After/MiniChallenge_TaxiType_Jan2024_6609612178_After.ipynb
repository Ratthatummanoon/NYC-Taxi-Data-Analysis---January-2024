{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENrSl0GlvwV9"
      },
      "source": [
        "# ğŸš• NYC Taxi Data Analysis - January 2024\n",
        "> **Project:** Big Data Engineering Mini-Challenge  \n",
        "> **Goal:** à¸„à¹‰à¸™à¸«à¸²à¸›à¸£à¸°à¹€à¸ à¸— Taxi à¸—à¸µà¹ˆà¸¡à¸µà¸¢à¸­à¸”à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (Rides) à¸ªà¸¹à¸‡à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹ƒà¸™à¹€à¸”à¸·à¸­à¸™à¸¡à¸à¸£à¸²à¸„à¸¡ 2024\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ—ï¸ Detailed Data Pipeline (AWS Implementation)\n",
        "à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¹‚à¸„à¹‰à¸”à¹ƒà¸™ Notebook à¸™à¸µà¹‰à¹à¸šà¹ˆà¸‡à¹€à¸›à¹‡à¸™ 5 à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸•à¸²à¸¡à¸«à¸¥à¸±à¸à¸à¸²à¸£ **Modern Data Lakehouse**:\n",
        "\n",
        "1.  ğŸš€ **Stage 1: AWS CONFIGURATION & DEPENDENCIES**\n",
        "    * **AWS_ACCESS_KEY**\n",
        "    * **AWS_SECRET_KEY**\n",
        "    * **AWS_SESSION_TOKEN**\n",
        "    * **REGION_NAME**\n",
        "    * **BUCKET_NAME**\n",
        "2.  ğŸ“¥ **Stage 2: INGEST (to AWS S3)**\n",
        "    * **AWS Service:** Amazon S3 (Simple Storage Service)\n",
        "    * **Action:** à¹‚à¸„à¹‰à¸”à¸ˆà¸°à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ Parquet à¸ˆà¸²à¸ Source à¹à¸¥à¸° Upload à¸‚à¸¶à¹‰à¸™ S3 Bucket à¸—à¸±à¸™à¸—à¸µ\n",
        "    * **Technique:** à¸ˆà¸±à¸”à¹€à¸à¹‡à¸šà¹à¸šà¸š **Partitioned Folder** (`/type=yellow`, `/type=green`) à¹€à¸à¸·à¹ˆà¸­à¹à¸¢à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¸£à¸°à¸”à¸±à¸š Storage\n",
        "\n",
        "3.  ğŸ—ï¸ **Stage 3: DEFINE SCHEMA (via Glue/Athena)**\n",
        "    * **AWS Service:** AWS Glue Data Catalog\n",
        "    * **Action:** à¹ƒà¸Šà¹‰à¸„à¸³à¸ªà¸±à¹ˆà¸‡ SQL (`CREATE EXTERNAL TABLE`) à¹€à¸à¸·à¹ˆà¸­à¸ªà¸£à¹‰à¸²à¸‡ \"à¸•à¸²à¸£à¸²à¸‡à¹€à¸ªà¸¡à¸·à¸­à¸™\" à¸Šà¸µà¹‰à¹„à¸›à¸¢à¸±à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™ S3\n",
        "    * **Concept:** **\"Schema-on-Read\"** â€” à¹€à¸£à¸²à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹à¸›à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡à¹† à¹à¸•à¹ˆà¹€à¸£à¸²à¸ªà¸£à¹‰à¸²à¸‡ Metadata à¹€à¸à¸·à¹ˆà¸­à¸šà¸­à¸à¹ƒà¸«à¹‰ Athena à¸£à¸¹à¹‰à¸§à¸´à¸˜à¸µà¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸±à¹‰à¸™\n",
        "\n",
        "4.  âš¡ **Stage 4: COMPUTE & AGGREGATE (Serverless)**\n",
        "    * **AWS Service:** AWS Athena\n",
        "    * **Action:** à¸ªà¹ˆà¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡ SQL (`SELECT count(*) ... UNION ALL ...`) à¹„à¸›à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸šà¸™ Cloud\n",
        "    * **Benefit:** à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ 23 à¸¥à¹‰à¸²à¸™à¹à¸–à¸§à¸¥à¸‡ RAM à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸•à¸±à¸§à¹€à¸­à¸‡ (No Out-of-Memory Errors) à¹à¸¥à¸°à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹€à¸£à¹‡à¸§à¸”à¹‰à¸§à¸¢ Presto Engine\n",
        "\n",
        "5.  ğŸ”„ **Stage 5: RETRIEVE RESULTS**\n",
        "    * **AWS Service:** AWS SDK (Boto3)\n",
        "    * **Action:** Python à¸£à¸­à¸£à¸±à¸šà¹€à¸‰à¸à¸²à¸° \"à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢\" (Aggregated Data) à¸—à¸µà¹ˆà¹€à¸¥à¹‡à¸à¸¡à¸²à¸à¹† à¸à¸¥à¸±à¸šà¸¡à¸²\n",
        "    \n",
        "6.  ğŸ“‘ **Stage 6: REPORTING**\n",
        "    * **Tool:** Pandas & Jupyter Notebook\n",
        "    * **Action:** à¸™à¸³à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸¡à¸²à¸ˆà¸±à¸”à¹€à¸£à¸µà¸¢à¸‡ (Ranking) à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸œà¸¥à¹€à¸›à¹‡à¸™à¸•à¸²à¸£à¸²à¸‡à¸ªà¸£à¸¸à¸›\n",
        "\n",
        "---\n",
        "\n",
        "## â˜ï¸ Cloud Architecture: Modern Data Lakehouse\n",
        "\n",
        "à¹€à¸£à¸²à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸ˆà¸²à¸à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸šà¸š Local Processing à¸¡à¸²à¹€à¸›à¹‡à¸™ **AWS Serverless Stack** à¹€à¸à¸·à¹ˆà¸­à¸£à¸­à¸‡à¸£à¸±à¸š **Scalability** à¹à¸¥à¸° **Cost Efficiency** à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¹à¸™à¸§à¸„à¸´à¸”à¸«à¸¥à¸±à¸à¸”à¸±à¸‡à¸™à¸µà¹‰:\n",
        "\n",
        "### ğŸ’¡ Key Concepts: ELT > ETL\n",
        "* **ELT (Extract, Load, Transform):** à¹€à¸™à¹‰à¸™à¸à¸²à¸£à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸° \"Load\" à¸¥à¸‡ Storage (S3) à¸—à¸±à¸™à¸—à¸µà¹€à¸à¸£à¸²à¸°à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¸¡à¸²à¸ à¹à¸¥à¹‰à¸§à¸„à¹ˆà¸­à¸¢ \"Transform\" à¸ à¸²à¸¢à¸«à¸¥à¸±à¸‡à¹€à¸¡à¸·à¹ˆà¸­à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™\n",
        "* **Serverless Querying:** à¹ƒà¸Šà¹‰ Athena à¸¢à¸´à¸‡ Query à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸”à¸¢à¸•à¸£à¸‡à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ Parquet à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ Provision Server à¸—à¸´à¹‰à¸‡à¹„à¸§à¹‰ (No-Ops)\n",
        "\n",
        "### ğŸ› ï¸ Tech Stack Selection\n",
        "| Service | Role | Key Benefit |\n",
        "| :--- | :--- | :--- |\n",
        "| **AWS S3** | **Storage** | à¹€à¸à¹‡à¸šà¹„à¸Ÿà¸¥à¹Œ Parquet (Decoupled Storage) à¸—à¸™à¸—à¸²à¸™à¸ªà¸¹à¸‡à¹à¸¥à¸°à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸à¸§à¹ˆà¸² Local Disk |\n",
        "| **AWS Glue** | **Metadata** | à¸—à¸³à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ Data Catalog à¹€à¸à¹‡à¸š Schema à¸à¸¥à¸²à¸‡ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ Hardcode |\n",
        "| **AWS Athena** | **Compute** | SQL Query Engine à¹à¸šà¸š Serverless à¸„à¸´à¸”à¹€à¸‡à¸´à¸™à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆ Scan à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Architecture Diagram\n",
        "\n",
        "à¹à¸œà¸™à¸ à¸²à¸à¸à¸²à¸£à¹„à¸«à¸¥à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (Data Flow) à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¸•à¹‰à¸™à¸—à¸²à¸‡à¸ˆà¸™à¸–à¸¶à¸‡à¸à¸²à¸£à¸­à¸­à¸à¸£à¸²à¸¢à¸‡à¸²à¸™:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYUqe8mxaXh5",
        "outputId": "e328c128-8b0f-4e15-f9da-c961da56cfd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "                           ğŸ—ºï¸  DATA PIPELINE MAP (NYC Taxi Data - AWS Edition)\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚  [STAGE 1: SOURCE]                                                                              â”‚\n",
            "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                              â”‚\n",
            "â”‚        ğŸŒ INTERNET SOURCE (NYC TLC Open Data)                                                   â”‚\n",
            "â”‚        â””â”€â”€ https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page                         â”‚\n",
            "â”‚            â€¢ Yellow Taxi:                                                                       â”‚\n",
            "â”‚            â€¢ Green Taxi:                                                                        â”‚\n",
            "â”‚            â€¢ FHV:                                                                               â”‚\n",
            "â”‚            â€¢ HVFHV:                                                                             â”‚\n",
            "â”‚            ğŸ“¦ Format: Apache Parquet (Columnar, Compressed)                                     â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "                                              â”‚\n",
            "                                              â”‚ 1ï¸âƒ£ INGEST (Python + urllib + boto3)\n",
            "                                              â”‚    â€¢ Download Parquet files from source\n",
            "                                              â”‚    â€¢ Stream upload to S3 bucket\n",
            "                                              â”‚    â€¢ Organize with Hive-style partitioning\n",
            "                                              â–¼\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚  [STAGE 2: STORAGE - DATA LAKE]                                                                 â”‚\n",
            "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚\n",
            "â”‚        ğŸ—‚ï¸ AWS S3 (Simple Storage Service)                                                       â”‚\n",
            "â”‚        â””â”€â”€ s3://cs341-taxi-{student_id}-bucket/                                                 â”‚\n",
            "â”‚            â””â”€â”€ raw_data/                                                                        â”‚\n",
            "â”‚                â”œâ”€â”€ type=yellow/   â†’ yellow_tripdata_2024-01.parquet                             â”‚\n",
            "â”‚                â”œâ”€â”€ type=green/    â†’ green_tripdata_2024-01.parquet                              â”‚\n",
            "â”‚                â”œâ”€â”€ type=fhv/      â†’ fhv_tripdata_2024-01.parquet                                â”‚\n",
            "â”‚                â””â”€â”€ type=hvfhv/    â†’ fhvhv_tripdata_2024-01.parquet                              â”‚\n",
            "â”‚                                                                                                 â”‚\n",
            "â”‚        ğŸ’¡ Key Benefits:                                                                         â”‚\n",
            "â”‚            â€¢ Decoupled storage (compute-independent)                                            â”‚\n",
            "â”‚            â€¢ 99.999999999% durability (11 nines)                                                â”‚\n",
            "â”‚            â€¢ Pay only for what you store (~$0.023/GB/month)                                     â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "                                              â”‚\n",
            "                                              â”‚ 2ï¸âƒ£ DEFINE SCHEMA (CREATE EXTERNAL TABLE)\n",
            "                                              â”‚    â€¢ DDL statements via Athena\n",
            "                                              â”‚    â€¢ No data movement (Schema-on-Read)\n",
            "                                              â”‚    â€¢ Maps S3 locations to SQL tables\n",
            "                                              â–¼\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚  [STAGE 3: METADATA LAYER - DATA CATALOG]                                                       â”‚\n",
            "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚\n",
            "â”‚        ğŸ“š AWS Glue Data Catalog                                                                 â”‚\n",
            "â”‚        â””â”€â”€ Database: taxi_analysis_db                                                           â”‚\n",
            "â”‚            â”œâ”€â”€ Table: yellow_taxi  (19 columns: VendorID, pickup_datetime, ...)                 â”‚\n",
            "â”‚            â”œâ”€â”€ Table: green_taxi   (20 columns: VendorID, lpep_pickup_datetime, ...)            â”‚\n",
            "â”‚            â”œâ”€â”€ Table: fhv_taxi     (7 columns: dispatching_base_num, pickup_datetime, ...)      â”‚\n",
            "â”‚            â””â”€â”€ Table: hvfhv_taxi   (24 columns: hvfhs_license_num, pickup_datetime, ...)        â”‚\n",
            "â”‚                                                                                                 â”‚\n",
            "â”‚        ğŸ’¡ Key Concept: \"Schema-on-Read\"                                                         â”‚\n",
            "â”‚            â€¢ Data stays in original format (Parquet)                                            â”‚\n",
            "â”‚            â€¢ Schema applied when queried, not when stored                                       â”‚\n",
            "â”‚            â€¢ Flexible: can redefine schema without reprocessing data                            â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "                                              â”‚\n",
            "                                              â”‚ 3ï¸âƒ£ METADATA LINK\n",
            "                                              â”‚    â€¢ Glue Catalog â†’ Athena integration\n",
            "                                              â”‚    â€¢ Automatic schema discovery\n",
            "                                              â–¼\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚  [STAGE 4: COMPUTE LAYER - SERVERLESS SQL]                                                      â”‚\n",
            "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                      â”‚\n",
            "â”‚        âš¡ AWS Athena (Presto/Trino Engine)                                                       â”‚\n",
            "â”‚        â””â”€â”€ SQL Query Execution:                                                                 â”‚\n",
            "â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
            "â”‚            â”‚  SELECT 'Yellow Taxi' as taxi_type, count(*) as rides                        â”‚     â”‚\n",
            "â”‚            â”‚  FROM taxi_analysis_db.yellow_taxi                                           â”‚     â”‚\n",
            "â”‚            â”‚  UNION ALL                                                                   â”‚     â”‚\n",
            "â”‚            â”‚  SELECT 'Green Taxi' as taxi_type, count(*) as rides                         â”‚     â”‚\n",
            "â”‚            â”‚  FROM taxi_analysis_db.green_taxi                                            â”‚     â”‚\n",
            "â”‚            â”‚  ...                                                                         â”‚     â”‚\n",
            "â”‚            â”‚  ORDER BY rides DESC;                                                        â”‚     â”‚\n",
            "â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
            "â”‚                                                                                                 â”‚\n",
            "â”‚        ğŸ’¡ Key Benefits:                                                                         â”‚\n",
            "â”‚            â€¢ No servers to manage (Serverless)                                                  â”‚\n",
            "â”‚            â€¢ Processes ~23M rows in seconds                                                     â”‚\n",
            "â”‚            â€¢ Pay per query (~$5/TB scanned)                                                     â”‚\n",
            "â”‚            â€¢ Parquet = less data scanned = lower cost                                           â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "                                              â”‚\n",
            "                                              â”‚ 4ï¸âƒ£ RETRIEVE RESULTS (boto3 SDK)\n",
            "                                              â”‚    â€¢ Only aggregated data returned\n",
            "                                              â”‚    â€¢ ~4 rows instead of 23M rows\n",
            "                                              â”‚    â€¢ Minimal network transfer\n",
            "                                              â–¼\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚  [STAGE 5: REPORTING & VISUALIZATION]                                                           â”‚\n",
            "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚\n",
            "â”‚        ğŸ’» Jupyter Notebook (Local)                                                              â”‚\n",
            "â”‚        â””â”€â”€ Final Output:                                                                        â”‚\n",
            "â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
            "â”‚            â”‚  Rank   Taxi Type      Rides Count     Percentage          â”‚                       â”‚\n",
            "â”‚            â”‚  â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚                       â”‚\n",
            "â”‚            â”‚  1      HVFHV          20,XXX,XXX      XX.X%               â”‚                       â”‚\n",
            "â”‚            â”‚  2      Yellow Taxi     2,XXX,XXX      XX.X%               â”‚                       â”‚\n",
            "â”‚            â”‚  3      FHV               XXX,XXX       X.X%               â”‚                       â”‚\n",
            "â”‚            â”‚  4      Green Taxi         XX,XXX       X.X%               â”‚                       â”‚\n",
            "â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
            "â”‚                                                                                                 â”‚\n",
            "â”‚        ğŸ† Answer: Which taxi type has the most rides in January 2024?                           â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "  ğŸ”„ DATA FLOW SUMMARY:  Source â†’ S3 (Store) â†’ Glue (Catalog) â†’ Athena (Query) â†’ Notebook (Report)\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\"\"\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "                           ğŸ—ºï¸  DATA PIPELINE MAP (NYC Taxi Data - AWS Edition)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  [STAGE 1: SOURCE]                                                                              â”‚\n",
        "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                              â”‚\n",
        "â”‚        ğŸŒ INTERNET SOURCE (NYC TLC Open Data)                                                   â”‚\n",
        "â”‚        â””â”€â”€ https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page                         â”‚\n",
        "â”‚            â€¢ Yellow Taxi:                                                                       â”‚\n",
        "â”‚            â€¢ Green Taxi:                                                                        â”‚\n",
        "â”‚            â€¢ FHV:                                                                               â”‚\n",
        "â”‚            â€¢ HVFHV:                                                                             â”‚\n",
        "â”‚            ğŸ“¦ Format: Apache Parquet (Columnar, Compressed)                                     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                              â”‚\n",
        "                                              â”‚ 1ï¸âƒ£ INGEST (Python + urllib + boto3)\n",
        "                                              â”‚    â€¢ Download Parquet files from source\n",
        "                                              â”‚    â€¢ Stream upload to S3 bucket\n",
        "                                              â”‚    â€¢ Organize with Hive-style partitioning\n",
        "                                              â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  [STAGE 2: STORAGE - DATA LAKE]                                                                 â”‚\n",
        "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚\n",
        "â”‚        ğŸ—‚ï¸ AWS S3 (Simple Storage Service)                                                       â”‚\n",
        "â”‚        â””â”€â”€ s3://cs341-taxi-{student_id}-bucket/                                                 â”‚\n",
        "â”‚            â””â”€â”€ raw_data/                                                                        â”‚\n",
        "â”‚                â”œâ”€â”€ type=yellow/   â†’ yellow_tripdata_2024-01.parquet                             â”‚\n",
        "â”‚                â”œâ”€â”€ type=green/    â†’ green_tripdata_2024-01.parquet                              â”‚\n",
        "â”‚                â”œâ”€â”€ type=fhv/      â†’ fhv_tripdata_2024-01.parquet                                â”‚\n",
        "â”‚                â””â”€â”€ type=hvfhv/    â†’ fhvhv_tripdata_2024-01.parquet                              â”‚\n",
        "â”‚                                                                                                 â”‚\n",
        "â”‚        ğŸ’¡ Key Benefits:                                                                         â”‚\n",
        "â”‚            â€¢ Decoupled storage (compute-independent)                                            â”‚\n",
        "â”‚            â€¢ 99.999999999% durability (11 nines)                                                â”‚\n",
        "â”‚            â€¢ Pay only for what you store (~$0.023/GB/month)                                     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                              â”‚\n",
        "                                              â”‚ 2ï¸âƒ£ DEFINE SCHEMA (CREATE EXTERNAL TABLE)\n",
        "                                              â”‚    â€¢ DDL statements via Athena\n",
        "                                              â”‚    â€¢ No data movement (Schema-on-Read)\n",
        "                                              â”‚    â€¢ Maps S3 locations to SQL tables\n",
        "                                              â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  [STAGE 3: METADATA LAYER - DATA CATALOG]                                                       â”‚\n",
        "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚\n",
        "â”‚        ğŸ“š AWS Glue Data Catalog                                                                 â”‚\n",
        "â”‚        â””â”€â”€ Database: taxi_analysis_db                                                           â”‚\n",
        "â”‚            â”œâ”€â”€ Table: yellow_taxi  (19 columns: VendorID, pickup_datetime, ...)                 â”‚\n",
        "â”‚            â”œâ”€â”€ Table: green_taxi   (20 columns: VendorID, lpep_pickup_datetime, ...)            â”‚\n",
        "â”‚            â”œâ”€â”€ Table: fhv_taxi     (7 columns: dispatching_base_num, pickup_datetime, ...)      â”‚\n",
        "â”‚            â””â”€â”€ Table: hvfhv_taxi   (24 columns: hvfhs_license_num, pickup_datetime, ...)        â”‚\n",
        "â”‚                                                                                                 â”‚\n",
        "â”‚        ğŸ’¡ Key Concept: \"Schema-on-Read\"                                                         â”‚\n",
        "â”‚            â€¢ Data stays in original format (Parquet)                                            â”‚\n",
        "â”‚            â€¢ Schema applied when queried, not when stored                                       â”‚\n",
        "â”‚            â€¢ Flexible: can redefine schema without reprocessing data                            â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                              â”‚\n",
        "                                              â”‚ 3ï¸âƒ£ METADATA LINK\n",
        "                                              â”‚    â€¢ Glue Catalog â†’ Athena integration\n",
        "                                              â”‚    â€¢ Automatic schema discovery\n",
        "                                              â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  [STAGE 4: COMPUTE LAYER - SERVERLESS SQL]                                                      â”‚\n",
        "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                      â”‚\n",
        "â”‚        âš¡ AWS Athena (Presto/Trino Engine)                                                       â”‚\n",
        "â”‚        â””â”€â”€ SQL Query Execution:                                                                 â”‚\n",
        "â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
        "â”‚            â”‚  SELECT 'Yellow Taxi' as taxi_type, count(*) as rides                        â”‚     â”‚\n",
        "â”‚            â”‚  FROM taxi_analysis_db.yellow_taxi                                           â”‚     â”‚\n",
        "â”‚            â”‚  UNION ALL                                                                   â”‚     â”‚\n",
        "â”‚            â”‚  SELECT 'Green Taxi' as taxi_type, count(*) as rides                         â”‚     â”‚\n",
        "â”‚            â”‚  FROM taxi_analysis_db.green_taxi                                            â”‚     â”‚\n",
        "â”‚            â”‚  ...                                                                         â”‚     â”‚\n",
        "â”‚            â”‚  ORDER BY rides DESC;                                                        â”‚     â”‚\n",
        "â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
        "â”‚                                                                                                 â”‚\n",
        "â”‚        ğŸ’¡ Key Benefits:                                                                         â”‚\n",
        "â”‚            â€¢ No servers to manage (Serverless)                                                  â”‚\n",
        "â”‚            â€¢ Processes ~23M rows in seconds                                                     â”‚\n",
        "â”‚            â€¢ Pay per query (~$5/TB scanned)                                                     â”‚\n",
        "â”‚            â€¢ Parquet = less data scanned = lower cost                                           â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                              â”‚\n",
        "                                              â”‚ 4ï¸âƒ£ RETRIEVE RESULTS (boto3 SDK)\n",
        "                                              â”‚    â€¢ Only aggregated data returned\n",
        "                                              â”‚    â€¢ ~4 rows instead of 23M rows\n",
        "                                              â”‚    â€¢ Minimal network transfer\n",
        "                                              â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  [STAGE 5: REPORTING & VISUALIZATION]                                                           â”‚\n",
        "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚\n",
        "â”‚        ğŸ’» Jupyter Notebook (Local)                                                              â”‚\n",
        "â”‚        â””â”€â”€ Final Output:                                                                        â”‚\n",
        "â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
        "â”‚            â”‚  Rank   Taxi Type      Rides Count     Percentage          â”‚                       â”‚\n",
        "â”‚            â”‚  â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚                       â”‚\n",
        "â”‚            â”‚  1      HVFHV          20,XXX,XXX      XX.X%               â”‚                       â”‚\n",
        "â”‚            â”‚  2      Yellow Taxi     2,XXX,XXX      XX.X%               â”‚                       â”‚\n",
        "â”‚            â”‚  3      FHV               XXX,XXX       X.X%               â”‚                       â”‚\n",
        "â”‚            â”‚  4      Green Taxi         XX,XXX       X.X%               â”‚                       â”‚\n",
        "â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
        "â”‚                                                                                                 â”‚\n",
        "â”‚        ğŸ† Answer: Which taxi type has the most rides in January 2024?                           â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "  ğŸ”„ DATA FLOW SUMMARY:  Source â†’ S3 (Store) â†’ Glue (Catalog) â†’ Athena (Query) â†’ Notebook (Report)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAyW0_gZGj6q"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9rSLzPrGj6q"
      },
      "source": [
        "# ğŸš€ Stage 1: AWS CONFIGURATION & DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9NOJH47vwWA",
        "outputId": "ea071fcc-3198-443a-d9ce-841b61cd216a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.41.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting botocore\n",
            "  Downloading botocore-1.41.5-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.16.0,>=0.15.0 (from boto3)\n",
            "  Downloading s3transfer-0.15.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading boto3-1.41.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.41.5-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.15.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.41.5 botocore-1.41.5 jmespath-1.0.1 s3transfer-0.15.0\n",
            "âš™ï¸ Setting up AWS Environment...\n",
            "âœ… AWS Session Authenticated: us-east-1\n",
            "ğŸ¯ Target S3 Bucket: cs341-taxi-6609612178-bucket\n"
          ]
        }
      ],
      "source": [
        "# Data Pipeline Stage: SETUP\n",
        "!pip install boto3 pandas botocore\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from botocore.exceptions import NoCredentialsError\n",
        "\n",
        "print(\"âš™ï¸ Setting up AWS Environment...\")\n",
        "\n",
        "# ==========================================\n",
        "# âš ï¸ UPDATE YOUR CREDENTIALS (FROM LEARNER LAB)\n",
        "# ==========================================\n",
        "AWS_ACCESS_KEY = \"Your access key\" # à¹ƒà¸ªà¹ˆ Access Key\n",
        "AWS_SECRET_KEY = \"Your secret key\" # à¹ƒà¸ªà¹ˆ Secret Key\n",
        "AWS_SESSION_TOKEN = \"Your token session\" # à¹ƒà¸ªà¹ˆ Session Token\n",
        "REGION_NAME = \"us-east-1\" # region à¸—à¸µà¹ˆ lab à¸à¸³à¸«à¸™à¸”\n",
        "\n",
        "# âš ï¸ UPDATE YOUR BUCKET NAME: Must be globally unique\n",
        "# Reccommend: cs341-taxi-{student_id}-bucket\n",
        "BUCKET_NAME = \"cs341-taxi-6609612178-bucket\"\n",
        "\n",
        "# Initialize AWS Clients\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id=AWS_ACCESS_KEY,\n",
        "    aws_secret_access_key=AWS_SECRET_KEY,\n",
        "    aws_session_token=AWS_SESSION_TOKEN,\n",
        "    region_name=REGION_NAME\n",
        ")\n",
        "\n",
        "s3_client = session.client('s3')\n",
        "athena_client = session.client('athena')\n",
        "glue_client = session.client('glue')\n",
        "\n",
        "print(f\"âœ… AWS Session Authenticated: {REGION_NAME}\")\n",
        "print(f\"ğŸ¯ Target S3 Bucket: {BUCKET_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hUbqztEJZuV"
      },
      "source": [
        "# ğŸ“¥ Stage 2: DATA INGESTION TO DATA LAKE (S3)\n",
        "- Data Pipeline Stage: INGEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVQJ6yJkJm98",
        "outputId": "8f47f766-f9b5-4be1-ef87-08d6c4790d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Starting Data Ingestion to AWS S3...\n",
            "â¬‡ï¸ Processing yellow_tripdata_2024-01.parquet...\n",
            "   âœ… Uploaded to s3://cs341-taxi-6609612178-bucket/raw_data/type=yellow/yellow_tripdata_2024-01.parquet\n",
            "â¬‡ï¸ Processing green_tripdata_2024-01.parquet...\n",
            "   âœ… Uploaded to s3://cs341-taxi-6609612178-bucket/raw_data/type=green/green_tripdata_2024-01.parquet\n",
            "â¬‡ï¸ Processing fhv_tripdata_2024-01.parquet...\n",
            "   âœ… Uploaded to s3://cs341-taxi-6609612178-bucket/raw_data/type=fhv/fhv_tripdata_2024-01.parquet\n",
            "â¬‡ï¸ Processing fhvhv_tripdata_2024-01.parquet...\n",
            "   âœ… Uploaded to s3://cs341-taxi-6609612178-bucket/raw_data/type=hvfhv/fhvhv_tripdata_2024-01.parquet\n",
            "\n",
            "ğŸ¯ Data Lake Ingestion Completed!\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "# URLs à¸‚à¹‰à¸­à¸¡à¸¹à¸¥\n",
        "files_to_download = [\n",
        "    (\"yellow_tripdata_2024-01.parquet\", \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\", \"yellow\"),\n",
        "    (\"green_tripdata_2024-01.parquet\", \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-01.parquet\", \"green\"),\n",
        "    (\"fhv_tripdata_2024-01.parquet\", \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2024-01.parquet\", \"fhv\"),\n",
        "    (\"fhvhv_tripdata_2024-01.parquet\", \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet\", \"hvfhv\")\n",
        "]\n",
        "\n",
        "def upload_to_s3(file_name, url, folder_prefix):\n",
        "    \"\"\"Download from URL and stream upload to S3 directly\"\"\"\n",
        "    print(f\"â¬‡ï¸ Processing {file_name}...\")\n",
        "\n",
        "    # Download locally temporarily (optimization: could stream directly but keeping it simple)\n",
        "    if not os.path.exists(file_name):\n",
        "        urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "    # Upload to S3 (Partitioned by type)\n",
        "    s3_key = f\"raw_data/type={folder_prefix}/{file_name}\"\n",
        "    try:\n",
        "        s3_client.upload_file(file_name, BUCKET_NAME, s3_key)\n",
        "        print(f\"   âœ… Uploaded to s3://{BUCKET_NAME}/{s3_key}\")\n",
        "        # Clean up local file to save space\n",
        "        os.remove(file_name)\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Error: {e}\")\n",
        "\n",
        "# Create Bucket if not exists (Try/Catch for existing buckets)\n",
        "try:\n",
        "    s3_client.create_bucket(Bucket=BUCKET_NAME)\n",
        "except:\n",
        "    print(\"â„¹ï¸ Bucket might already exist or permission restricted (Continuing...)\")\n",
        "\n",
        "# Execute Ingestion\n",
        "print(\"ğŸš€ Starting Data Ingestion to AWS S3...\")\n",
        "for fname, url, prefix in files_to_download:\n",
        "    upload_to_s3(fname, url, prefix)\n",
        "\n",
        "print(\"\\nğŸ¯ Data Lake Ingestion Completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCDfvU9YJ5E_"
      },
      "source": [
        "# ğŸ”„ Stage 3: DEFINE SCHEMA (GLUE/ATHENA)\n",
        "- Data Pipeline Stage: TRANSFORM / DEFINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtAE27l8J6xq",
        "outputId": "36d370ae-8926-4039-acd9-37c20b7f54ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ—ï¸ Setting up Data Catalog...\n",
            "âœ… Database 'taxi_analysis_db' ready.\n",
            "   Creating table definition for: yellow_taxi\n",
            "   Creating table definition for: green_taxi\n",
            "   Creating table definition for: fhv_taxi\n",
            "   Creating table definition for: hvfhv_taxi\n",
            "âœ… Data Catalog Definitions Completed.\n"
          ]
        }
      ],
      "source": [
        "DATABASE_NAME = \"taxi_analysis_db\"\n",
        "RESULT_OUTPUT_LOCATION = f\"s3://{BUCKET_NAME}/athena_results/\"\n",
        "\n",
        "def run_athena_query(query, db=None):\n",
        "    context = {'Database': db} if db else {}\n",
        "    response = athena_client.start_query_execution(\n",
        "        QueryString=query,\n",
        "        QueryExecutionContext=context,\n",
        "        ResultConfiguration={'OutputLocation': RESULT_OUTPUT_LOCATION}\n",
        "    )\n",
        "    return response['QueryExecutionId']\n",
        "\n",
        "def wait_for_query(query_id):\n",
        "    while True:\n",
        "        status = athena_client.get_query_execution(QueryExecutionId=query_id)\n",
        "        state = status['QueryExecution']['Status']['State']\n",
        "        if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
        "            return state\n",
        "        time.sleep(1)\n",
        "\n",
        "print(\"ğŸ—ï¸ Setting up Data Catalog...\")\n",
        "\n",
        "# 1. Create Database\n",
        "create_db_query = f\"CREATE DATABASE IF NOT EXISTS {DATABASE_NAME};\"\n",
        "qid = run_athena_query(create_db_query, db=DATABASE_NAME) # Fixed: Pass DATABASE_NAME here\n",
        "if wait_for_query(qid) == 'SUCCEEDED':\n",
        "    print(f\"âœ… Database '{DATABASE_NAME}' ready.\")\n",
        "\n",
        "# 2. Create External Tables (Mapping S3 Parquet to SQL Table)\n",
        "# Technique: Hive Partitioning or just direct mapping.\n",
        "# Here we treat all files as one large dataset but categorized by the folder structure we created.\n",
        "# For simplicity in this mini-challenge, we will create one table per type or a view.\n",
        "# Let's create one main table and use the directory structure (Hive style) if we partitioned correctly,\n",
        "# but since schemas differ slightly, we create 4 external tables.\n",
        "\n",
        "tables_ddl = {\n",
        "    \"yellow_taxi\": f\"\"\"\n",
        "        CREATE EXTERNAL TABLE IF NOT EXISTS {DATABASE_NAME}.yellow_taxi (\n",
        "          VendorID bigint, tpep_pickup_datetime timestamp, tpep_dropoff_datetime timestamp, passenger_count double,\n",
        "          trip_distance double, RatecodeID double, store_and_fwd_flag string, PULocationID bigint, DOLocationID bigint,\n",
        "          payment_type bigint, fare_amount double, extra double, mta_tax double, tip_amount double, tolls_amount double,\n",
        "          improvement_surcharge double, total_amount double, congestion_surcharge double, Airport_fee double\n",
        "        ) STORED AS PARQUET LOCATION 's3://{BUCKET_NAME}/raw_data/type=yellow/'\n",
        "    \"\"\",\n",
        "    \"green_taxi\": f\"\"\"\n",
        "        CREATE EXTERNAL TABLE IF NOT EXISTS {DATABASE_NAME}.green_taxi (\n",
        "          VendorID bigint, lpep_pickup_datetime timestamp, lpep_dropoff_datetime timestamp, store_and_fwd_flag string,\n",
        "          RatecodeID double, PULocationID bigint, DOLocationID bigint, passenger_count double, trip_distance double,\n",
        "          fare_amount double, extra double, mta_tax double, tip_amount double, tolls_amount double, ehail_fee double,\n",
        "          improvement_surcharge double, total_amount double, payment_type double, trip_type double, congestion_surcharge double\n",
        "        ) STORED AS PARQUET LOCATION 's3://{BUCKET_NAME}/raw_data/type=green/'\n",
        "    \"\"\",\n",
        "    \"fhv_taxi\": f\"\"\"\n",
        "        CREATE EXTERNAL TABLE IF NOT EXISTS {DATABASE_NAME}.fhv_taxi (\n",
        "          dispatching_base_num string, pickup_datetime timestamp, dropOff_datetime timestamp,\n",
        "          PUlocationID double, DOlocationID double, SR_Flag double, Affiliated_base_number string\n",
        "        ) STORED AS PARQUET LOCATION 's3://{BUCKET_NAME}/raw_data/type=fhv/'\n",
        "    \"\"\",\n",
        "    \"hvfhv_taxi\": f\"\"\"\n",
        "        CREATE EXTERNAL TABLE IF NOT EXISTS {DATABASE_NAME}.hvfhv_taxi (\n",
        "           hvfhs_license_num string, dispatching_base_num string, originating_base_num string, request_datetime timestamp,\n",
        "           on_scene_datetime timestamp, pickup_datetime timestamp, dropoff_datetime timestamp, PULocationID bigint,\n",
        "           DOLocationID bigint, trip_miles double, trip_time bigint, base_passenger_fare double, tolls double,\n",
        "           bcf double, sales_tax double, congestion_surcharge double, airport_fee double, tips double, driver_pay double,\n",
        "           shared_request_flag string, shared_match_flag string, access_a_ride_flag string, wav_request_flag string, wav_match_flag string\n",
        "        ) STORED AS PARQUET LOCATION 's3://{BUCKET_NAME}/raw_data/type=hvfhv/'\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "for name, ddl in tables_ddl.items():\n",
        "    print(f\"   Creating table definition for: {name}\")\n",
        "    qid = run_athena_query(ddl, DATABASE_NAME)\n",
        "    wait_for_query(qid)\n",
        "\n",
        "print(\"âœ… Data Catalog Definitions Completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbGH73xiLvmn"
      },
      "source": [
        "# ğŸ“Š Stage 4: AGGREGATE ON CLOUD (ATHENA)\n",
        "# Data Pipeline Stage: AGGREGATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdYS1cVyLzxF",
        "outputId": "e2dfaa96-4f83-479b-dcf1-d0e5439603be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš¡ Running Serverless SQL Query on AWS Athena...\n",
            "â³ Query Execution ID: b3aadcac-bdfb-482c-a02a-e361fa5ac3c7\n",
            "âœ… Query Succeeded!\n"
          ]
        }
      ],
      "source": [
        "print(\"âš¡ Running Serverless SQL Query on AWS Athena...\")\n",
        "\n",
        "# SQL Query: Count rows from each table and combine results\n",
        "# This runs on AWS infrastructure, not your notebook kernel.\n",
        "aggregate_query = f\"\"\"\n",
        "SELECT 'Yellow Taxi' as taxi_type, count(*) as rides FROM {DATABASE_NAME}.yellow_taxi\n",
        "UNION ALL\n",
        "SELECT 'Green Taxi' as taxi_type, count(*) as rides FROM {DATABASE_NAME}.green_taxi\n",
        "UNION ALL\n",
        "SELECT 'FHV' as taxi_type, count(*) as rides FROM {DATABASE_NAME}.fhv_taxi\n",
        "UNION ALL\n",
        "SELECT 'HVFHV' as taxi_type, count(*) as rides FROM {DATABASE_NAME}.hvfhv_taxi\n",
        "ORDER BY rides DESC;\n",
        "\"\"\"\n",
        "\n",
        "# Execute Query\n",
        "query_id = run_athena_query(aggregate_query, DATABASE_NAME)\n",
        "print(f\"â³ Query Execution ID: {query_id}\")\n",
        "\n",
        "# Wait for completion\n",
        "status = wait_for_query(query_id)\n",
        "if status == 'SUCCEEDED':\n",
        "    print(\"âœ… Query Succeeded!\")\n",
        "\n",
        "    # Get Results\n",
        "    results_paginator = athena_client.get_query_results(QueryExecutionId=query_id)\n",
        "\n",
        "    # Convert Athena Result to Pandas DataFrame\n",
        "    # (Handling the complex Athena JSON response)\n",
        "    rows = []\n",
        "    for page in results_paginator['ResultSet']['Rows']:\n",
        "        rows.append([col.get('VarCharValue', '') for col in page['Data']])\n",
        "\n",
        "    # First row is header\n",
        "    df_results = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "    # Convert types\n",
        "    df_results['rides'] = df_results['rides'].astype(int)\n",
        "\n",
        "else:\n",
        "    print(f\"âŒ Query Failed: {status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12BoTinmL4Op"
      },
      "source": [
        "# ğŸ“‹ Stage 5: REPORT & VISUALIZATION\n",
        "# Data Pipeline Stage: REPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP_wnQAdMGO3",
        "outputId": "82aa06e1-438d-4716-c3ef-b279750a33f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ˆ FINAL RESULTS - NYC Taxi Rides Analysis (Cloud Edition)\n",
            "======================================================================\n",
            "Rank   Taxi Type       Rides Count     Percentage\n",
            "-------------------------------------------------------\n",
            "1      HVFHV             19,663,930     82.0%\n",
            "2      Yellow Taxi        2,964,624     12.4%\n",
            "3      FHV                1,290,116      5.4%\n",
            "4      Green Taxi            56,551      0.2%\n",
            "-------------------------------------------------------\n",
            "TOTAL                    23,975,221   100.0%\n",
            "\n",
            "ğŸ† Top taxi type (Jan 2024): HVFHV â€” 19,663,930 rides\n",
            "\n",
            "ğŸ’¡ AWS Architecture Benefits:\n",
            "1. Scalability: S3 can hold PB of data.\n",
            "2. Serverless: No EC2 instances were managed.\n",
            "3. Cost: Paid only for S3 storage & query scan time.\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ“ˆ FINAL RESULTS - NYC Taxi Rides Analysis (Cloud Edition)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Calculate Percentage\n",
        "total_rides = df_results['rides'].sum()\n",
        "df_results['percentage'] = (df_results['rides'] / total_rides) * 100\n",
        "\n",
        "# Display Table\n",
        "print(f\"{'Rank':<6} {'Taxi Type':<15} {'Rides Count':<15} {'Percentage':<10}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for idx, row in df_results.iterrows():\n",
        "    print(f\"{idx+1:<6} {row['taxi_type']:<15} {row['rides']:>12,} {row['percentage']:>8.1f}%\")\n",
        "\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'TOTAL':<22} {total_rides:>12,} {'100.0%':>8}\")\n",
        "\n",
        "top_type = df_results.iloc[0]\n",
        "print(f\"\\nğŸ† Top taxi type (Jan 2024): {top_type['taxi_type']} â€” {top_type['rides']:,} rides\")\n",
        "\n",
        "print(\"\\nğŸ’¡ AWS Architecture Benefits:\")\n",
        "print(\"1. Scalability: S3 can hold PB of data.\")\n",
        "print(\"2. Serverless: No EC2 instances were managed.\")\n",
        "print(\"3. Cost: Paid only for S3 storage & query scan time.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4hBrxQhaXh-"
      },
      "source": [
        "# ğŸ¯ **à¸ªà¸£à¸¸à¸›à¸„à¸³à¸•à¸­à¸šà¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ (FINAL CONCLUSION)**\n",
        "\n",
        "## **à¸„à¸³à¸•à¸­à¸šà¹‚à¸ˆà¸—à¸¢à¹Œà¸—à¸µà¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™:**\n",
        "# A. Pipeline Architecture Diagram: Desbribe how to work\n",
        "### âš™ï¸ How it Works: The Serverless Data Pipeline\n",
        "à¸­à¸˜à¸´à¸šà¸²à¸¢à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸•à¸²à¸¡ Data Flow 5 à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™ (Ingest â†’ Store â†’ Clean/Transform â†’ Query/Aggregate â†’ Output):\n",
        "\n",
        "**1. Ingest (à¸™à¸³à¹€à¸‚à¹‰à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥):**\n",
        "* à¹ƒà¸Šà¹‰ Python Script (`boto3`) à¸—à¸³à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ Ingestion Layer\n",
        "* à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸”à¸´à¸š (Parquet) à¸ˆà¸²à¸ NYC Taxi Source à¹à¸¥à¸°à¸—à¸³à¸à¸²à¸£ **Stream Upload** à¸‚à¸¶à¹‰à¸™à¸ªà¸¹à¹ˆ AWS S3 à¸—à¸±à¸™à¸—à¸µà¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸±à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¥à¸‡ Disk à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡ local à¸™à¸²à¸™\n",
        "\n",
        "**2. Store (à¸ˆà¸±à¸”à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥):**\n",
        "* à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸–à¸¹à¸à¸ˆà¸±à¸”à¹€à¸à¹‡à¸šà¹ƒà¸™ **AWS S3** (Data Lake) à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š **Partitioned Folder** (`/type=yellow`, `/type=green`)\n",
        "* à¸à¸²à¸£à¹€à¸à¹‡à¸šà¹à¸šà¸šà¸™à¸µà¹‰à¹à¸¢à¸à¸ªà¹ˆà¸§à¸™ Storage à¸­à¸­à¸à¸ˆà¸²à¸ Compute (Decoupled Storage) à¸—à¸³à¹ƒà¸«à¹‰à¸•à¹‰à¸™à¸—à¸¸à¸™à¸•à¹ˆà¸³à¹à¸¥à¸°à¸‚à¸¢à¸²à¸¢à¸‚à¸™à¸²à¸”à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸ˆà¸³à¸à¸±à¸”\n",
        "\n",
        "**3. Clean/Transform (à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¹à¸¥à¸°à¹à¸›à¸¥à¸‡à¸£à¸¹à¸›):**\n",
        "* à¹ƒà¸Šà¹‰à¸«à¸¥à¸±à¸à¸à¸²à¸£ **Schema-on-Read** à¸œà¹ˆà¸²à¸™ **AWS Glue Data Catalog**\n",
        "* à¹à¸—à¸™à¸—à¸µà¹ˆà¸ˆà¸°à¹€à¸ªà¸µà¸¢à¹€à¸§à¸¥à¸²à¹à¸›à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œ (ETL) à¹€à¸£à¸²à¹ƒà¸Šà¹‰à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ **External Table** à¹€à¸à¸·à¹ˆà¸­ \"à¸à¸³à¸«à¸™à¸”à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡\" (Define Schema) à¸„à¸£à¸­à¸šà¸¥à¸‡à¹„à¸›à¸šà¸™à¹„à¸Ÿà¸¥à¹Œà¸”à¸´à¸š à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸ªà¸¡à¸·à¸­à¸™à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸–à¸¹à¸ Clean à¹à¸¥à¸° Transform à¹€à¸›à¹‡à¸™à¸•à¸²à¸£à¸²à¸‡à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¹à¸¥à¹‰à¸§\n",
        "\n",
        "**4. Query/Aggregate (à¸ªà¸­à¸šà¸–à¸²à¸¡à¹à¸¥à¸°à¸£à¸§à¸šà¸£à¸§à¸¡à¸œà¸¥):**\n",
        "* à¹ƒà¸Šà¹‰ **AWS Athena** (Serverless SQL Engine) à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥\n",
        "* à¸ªà¹ˆà¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡ SQL (`SELECT count(*) ...`) à¹„à¸›à¸—à¸³à¸‡à¸²à¸™à¸šà¸™ Cloud à¸‹à¸¶à¹ˆà¸‡ Athena à¸ˆà¸°à¸—à¸³à¸à¸²à¸£à¸ªà¹à¸à¸™à¹„à¸Ÿà¸¥à¹Œà¸šà¸™ S3 à¹à¸¥à¸°à¸£à¸§à¸šà¸£à¸§à¸¡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ (Aggregation) à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§\n",
        "\n",
        "**5. Output (à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ):**\n",
        "* à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ (Aggregated Results) à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸à¸ˆà¸°à¸–à¸¹à¸à¸ªà¹ˆà¸‡à¸à¸¥à¸±à¸šà¸¡à¸²à¸¢à¸±à¸‡ **Jupyter Notebook**\n",
        "* à¹ƒà¸Šà¹‰ **Pandas** à¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸š (Ranking) à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸œà¸¥à¹€à¸›à¹‡à¸™à¸•à¸²à¸£à¸²à¸‡à¸ªà¸£à¸¸à¸›à¸„à¸³à¸•à¸­à¸š (Final Answer)\n",
        "---\n",
        "# B. Final Result\n",
        "### ğŸ“Š **à¸•à¸²à¸£à¸²à¸‡à¸ªà¸£à¸¸à¸›à¸ˆà¸³à¸™à¸§à¸™ rides (à¹€à¸£à¸µà¸¢à¸‡à¸ˆà¸²à¸à¸¡à¸²à¸à¹„à¸›à¸™à¹‰à¸­à¸¢)**\n",
        "| à¸­à¸±à¸™à¸”à¸±à¸š | à¸›à¸£à¸°à¹€à¸ à¸— Taxi | à¸ˆà¸³à¸™à¸§à¸™ Rides | à¹€à¸›à¸­à¸£à¹Œà¹€à¸‹à¹‡à¸™à¸•à¹Œ |\n",
        "|--------|-------------|-------------|-----------|\n",
        "| 1      | **HVFHV**   | **19,663,930** | **82.0%** |\n",
        "| 2      | Yellow Taxi | 2,964,624   | 12.4%     |\n",
        "| 3      | FHV         | 1,290,116   | 5.4%      |\n",
        "| 4      | Green Taxi  | 56,551      | 0.2%      |\n",
        "\n",
        "### ğŸ“ **à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ªà¸£à¸¸à¸›**\n",
        "**ğŸ† Top taxi type (Jan 2024): HVFHV â€” 19,663,930 rides**\n",
        "\n",
        "---\n",
        "# C. Reflection\n",
        "### 1. Comparison: Before (Local) vs. After (Cloud)\n",
        "| Aspect | Before (Local / DuckDB) | After (AWS Cloud / S3 + Athena) |\n",
        "| :--- | :--- | :--- |\n",
        "| **Storage** | à¹€à¸à¹‡à¸šà¹ƒà¸™ Hard Disk à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸•à¸±à¸§à¹€à¸­à¸‡ (à¸à¸´à¸™à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆ) | à¹€à¸à¹‡à¸šà¹ƒà¸™ **S3 Data Lake** (à¸£à¸­à¸‡à¸£à¸±à¸šà¸£à¸°à¸”à¸±à¸š Petabyte) |\n",
        "| **Compute** | à¹ƒà¸Šà¹‰ RAM/CPU à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸•à¸±à¸§à¹€à¸­à¸‡ (à¸–à¹‰à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸à¹ˆ à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸„à¹‰à¸²à¸‡) | à¹ƒà¸Šà¹‰ **Athena Serverless** (à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸šà¸™ Cloud à¹€à¸£à¹‡à¸§à¹à¸¥à¸°à¹à¸£à¸‡) |\n",
        "| **Scalability** | à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸ˆà¸³à¸à¸±à¸”à¹à¸„à¹ˆà¸ªà¹€à¸›à¸„à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸—à¸µà¹ˆà¸¡à¸µ | **Unlimited Scalability** à¸£à¸­à¸‡à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸«à¸²à¸¨à¸²à¸¥à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µ |\n",
        "| **Cost** | à¸Ÿà¸£à¸µ (à¹à¸•à¹ˆà¹€à¸ªà¸µà¸¢à¸„à¹ˆà¸²à¹„à¸Ÿ/à¸„à¹ˆà¸²à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡) | **Pay-as-you-go** à¸ˆà¹ˆà¸²à¸¢à¸•à¸²à¸¡à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¹€à¸à¹‡à¸šà¹à¸¥à¸°à¸›à¸£à¸´à¸¡à¸²à¸“à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆ Scan |\n",
        "\n",
        "### 2. What was the most difficult part?\n",
        "* **AWS Configuration & IAM:** à¸„à¸§à¸²à¸¡à¸¢à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸„à¸·à¸­à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¹€à¸£à¸·à¹ˆà¸­à¸‡ **Credentials (Access Key/Secret Key)** à¹à¸¥à¸°à¸à¸²à¸£à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¹€à¸£à¸·à¹ˆà¸­à¸‡ Permission à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¸­à¸™à¸¸à¸à¸²à¸•à¹ƒà¸«à¹‰ Athena à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡ S3 à¹„à¸”à¹‰ à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£à¸à¹‡à¸•à¸²à¸¡ à¸à¸²à¸£à¹ƒà¸Šà¹‰ **Learner Lab** à¸Šà¹ˆà¸§à¸¢à¸¥à¸”à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¹€à¸£à¸·à¹ˆà¸­à¸‡ Permission à¸¥à¸‡à¹„à¸›à¹„à¸”à¹‰à¸šà¹‰à¸²à¸‡ à¹à¸•à¹ˆà¸•à¹‰à¸­à¸‡à¸„à¸­à¸¢à¸£à¸°à¸§à¸±à¸‡à¹€à¸£à¸·à¹ˆà¸­à¸‡ Session Token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸\n",
        "* **Schema-on-Read Concept:** à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸²à¹€à¸£à¸²à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ \"Create Table\" à¹à¸šà¸š Database à¸—à¸±à¹ˆà¸§à¹„à¸›à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸¢à¸¹à¹ˆà¸‚à¹‰à¸²à¸‡à¹ƒà¸™ à¹à¸•à¹ˆà¹€à¸›à¹‡à¸™à¸à¸²à¸£à¸Šà¸µà¹‰ (Point) à¹„à¸›à¸—à¸µà¹ˆ S3 à¹à¸—à¸™ à¸—à¸³à¹ƒà¸«à¹‰à¸•à¹‰à¸­à¸‡à¸£à¸°à¸§à¸±à¸‡à¹€à¸£à¸·à¹ˆà¸­à¸‡ Path à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¹à¸¡à¹ˆà¸™à¸¢à¸³\n",
        "\n",
        "### 3. What did I learn?\n",
        "* **Modern Data Architecture:** à¹„à¸”à¹‰à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ **Data Lakehouse** à¸—à¸µà¹ˆà¹à¸¢à¸ Storage (S3) à¸­à¸­à¸à¸ˆà¸²à¸ Compute (Athena) à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸±à¸”à¹€à¸ˆà¸™\n",
        "* **ELT Process:** à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£ **Extract-Load-Transform** à¸—à¸µà¹ˆà¹€à¸™à¹‰à¸™à¹€à¸­à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸¶à¹‰à¸™ Cloud à¹ƒà¸«à¹‰à¹€à¸£à¹‡à¸§à¸à¹ˆà¸­à¸™ (Load to S3) à¹à¸¥à¹‰à¸§à¸„à¹ˆà¸­à¸¢à¹ƒà¸Šà¹‰à¸à¸¥à¸±à¸‡à¸‚à¸­à¸‡ Cloud à¸¡à¸²à¸ˆà¸±à¸”à¸à¸²à¸£à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¸«à¸¥à¸±à¸‡ (Query via Athena)\n",
        "* **Serverless Power:** à¹€à¸«à¹‡à¸™à¸ à¸²à¸à¸Šà¸±à¸”à¹€à¸ˆà¸™à¸§à¹ˆà¸² Serverless à¸Šà¹ˆà¸§à¸¢à¸¥à¸”à¸‡à¸²à¸™ Maintenance (No-Ops) à¹à¸¥à¸°à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Big Data à¹„à¸”à¹‰à¸ˆà¸£à¸´à¸‡\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
